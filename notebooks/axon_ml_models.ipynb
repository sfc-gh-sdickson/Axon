{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Axon ML Models - Model Registry\n",
        "\n",
        "This notebook trains ML models for the Axon Intelligence Agent:\n",
        "- **Evidence Upload Volume Forecasting** - Predict future monthly evidence_upload_volume\n",
        "- **Agency Churn Prediction** - Classify agencies at risk of churning\n",
        "- **Device Deployment Success** - Predict which device deployments will be successful\n",
        "\n",
        "All models are registered to Snowflake Model Registry and can be added as tools to the Intelligence Agent.\n",
        "\n",
        "## Prerequisites\n",
        "\n",
        "**Required Packages** (configured automatically):\n",
        "- `snowflake-ml-python`\n",
        "- `scikit-learn`\n",
        "- `xgboost`\n",
        "- `matplotlib`\n",
        "\n",
        "**Database Context:**\n",
        "- **Database:** AXON_INTELLIGENCE  \n",
        "- **Schema:** ANALYTICS  \n",
        "- **Warehouse:** AXON_WH\n",
        "\n",
        "**Note:** This notebook uses Snowflake Model Registry. Ensure you have appropriate permissions to create and register models.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import Required Packages\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import Python packages\n",
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Import Snowpark\n",
        "from snowflake.snowpark.context import get_active_session\n",
        "import snowflake.snowpark.functions as F\n",
        "import snowflake.snowpark.types as T\n",
        "from snowflake.snowpark import Window\n",
        "\n",
        "# Import Snowpark ML\n",
        "from snowflake.ml.modeling.preprocessing import StandardScaler, OneHotEncoder\n",
        "from snowflake.ml.modeling.pipeline import Pipeline\n",
        "from snowflake.ml.modeling.linear_model import LinearRegression, LogisticRegression\n",
        "from snowflake.ml.modeling.ensemble import RandomForestClassifier\n",
        "from snowflake.ml.modeling.metrics import mean_squared_error, mean_absolute_error, accuracy_score, roc_auc_score\n",
        "from snowflake.ml.registry import Registry\n",
        "\n",
        "print(\"✅ Packages imported successfully\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Connect to Snowflake\n",
        "\n",
        "Get active session and set context to Axon database.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get active Snowflake session\n",
        "session = get_active_session()\n",
        "\n",
        "# Set context\n",
        "session.use_database('AXON_INTELLIGENCE')\n",
        "session.use_schema('ANALYTICS')\n",
        "session.use_warehouse('AXON_WH')\n",
        "\n",
        "print(f\"✅ Connected - Role: {session.get_current_role()}\")\n",
        "print(f\"   Warehouse: {session.get_current_warehouse()}\")\n",
        "print(f\"   Database.Schema: {session.get_fully_qualified_current_schema()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# MODEL 1: Evidence Upload Volume Forecasting\n",
        "\n",
        "Predict future monthly evidence_upload_volume using historical order data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Prepare Revenue Training Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get monthly evidence upload volume data with features\n",
        "evidence_upload_volume_df = session.sql(\"\"\"\n",
        "SELECT\n",
        "    DATE_TRUNC('month', upload_date)::DATE AS upload_month,\n",
        "    MONTH(upload_date) AS month_num,\n",
        "    YEAR(upload_date) AS year_num,\n",
        "    COUNT(DISTINCT evidence_id)::FLOAT AS total_evidence_upload_volume,\n",
        "    COUNT(DISTINCT deployment_id)::FLOAT AS deployment_count,\n",
        "    COUNT(DISTINCT agency_id)::FLOAT AS agency_count,\n",
        "    AVG(file_size_mb)::FLOAT AS avg_file_size_mb\n",
        "FROM RAW.EVIDENCE_UPLOADS\n",
        "WHERE upload_date >= DATEADD('month', -30, CURRENT_DATE())\n",
        "  AND evidence_status = 'ACTIVE'\n",
        "GROUP BY DATE_TRUNC('month', upload_date), MONTH(upload_date), YEAR(upload_date)\n",
        "ORDER BY upload_month\n",
        "\"\"\")\n",
        "\n",
        "print(f\"Evidence upload volume data: {evidence_upload_volume_df.count()} months\")\n",
        "evidence_upload_volume_df.show(5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Split Data and Train Revenue Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train/test split (last 6 months for testing)\n",
        "train_evidence_upload_volume = evidence_upload_volume_df.filter(F.col(\"UPLOAD_MONTH\") < F.dateadd(\"month\", F.lit(-6), F.current_date()))\n",
        "test_evidence_upload_volume = evidence_upload_volume_df.filter(F.col(\"UPLOAD_MONTH\") >= F.dateadd(\"month\", F.lit(-6), F.current_date()))\n",
        "\n",
        "# Drop UPLOAD_MONTH (DATE type not supported in pipeline)\n",
        "train_evidence_upload_volume = train_evidence_upload_volume.drop(\"UPLOAD_MONTH\")\n",
        "test_evidence_upload_volume = test_evidence_upload_volume.drop(\"UPLOAD_MONTH\")\n",
        "\n",
        "# Create pipeline\n",
        "evidence_upload_volume_pipeline = Pipeline([\n",
        "    (\"Scaler\", StandardScaler(\n",
        "        input_cols=[\"MONTH_NUM\", \"DEPLOYMENT_COUNT\", \"AGENCY_COUNT\", \"AVG_FILE_SIZE_MB\"],\n",
        "        output_cols=[\"MONTH_NUM_SCALED\", \"DEPLOYMENT_COUNT_SCALED\", \"AGENCY_COUNT_SCALED\", \"AVG_FILE_SIZE_MB_SCALED\"]\n",
        "    )),\n",
        "    (\"LinearRegression\", LinearRegression(\n",
        "        label_cols=[\"TOTAL_EVIDENCE_UPLOAD_VOLUME\"],\n",
        "        output_cols=[\"PREDICTED_EVIDENCE_UPLOAD_VOLUME\"]\n",
        "    ))\n",
        "])\n",
        "\n",
        "# Train model\n",
        "evidence_upload_volume_pipeline.fit(train_evidence_upload_volume)\n",
        "print(\"✅ Evidence upload volume forecasting model trained\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluate and Register Revenue Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Make predictions on test set\n",
        "test_predictions = evidence_upload_volume_pipeline.predict(test_evidence_upload_volume)\n",
        "\n",
        "# Calculate metrics\n",
        "mae = mean_absolute_error(df=test_predictions, y_true_col_names=\"TOTAL_EVIDENCE_UPLOAD_VOLUME\", y_pred_col_names=\"PREDICTED_EVIDENCE_UPLOAD_VOLUME\")\n",
        "mse = mean_squared_error(df=test_predictions, y_true_col_names=\"TOTAL_EVIDENCE_UPLOAD_VOLUME\", y_pred_col_names=\"PREDICTED_EVIDENCE_UPLOAD_VOLUME\")\n",
        "rmse = mse ** 0.5\n",
        "\n",
        "metrics = {\"mae\": round(mae, 2), \"rmse\": round(rmse, 2)}\n",
        "print(f\"Model metrics: {metrics}\")\n",
        "\n",
        "# Register model\n",
        "reg = Registry(session)\n",
        "reg.log_model(\n",
        "    model=evidence_upload_volume_pipeline,\n",
        "    model_name=\"EVIDENCE_VOLUME_PREDICTOR\",\n",
        "    version_name=\"V1\",\n",
        "    comment=\"Predicts monthly evidence upload volume based on historical deployment and storage patterns using Linear Regression\",\n",
        "    metrics=metrics\n",
        ")\n",
        "\n",
        "print(\"✅ Evidence volume model registered to Model Registry as EVIDENCE_VOLUME_PREDICTOR\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# MODEL 2: Agency Churn Prediction\n",
        "\n",
        "Classify agencies as likely to churn or not based on behavior patterns.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Prepare Churn Training Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get agency features for churn prediction\n",
        "churn_df = session.sql(\"\"\"\n",
        "SELECT\n",
        "    a.agency_id,\n",
        "    a.agency_type AS agency_segment,\n",
        "    a.jurisdiction_type AS jurisdiction,\n",
        "    a.lifetime_value::FLOAT AS lifetime_value,\n",
        "    a.population_served::FLOAT AS population_served,\n",
        "    -- Recent orders (last 3 months)\n",
        "    COUNT(DISTINCT CASE WHEN o.order_date >= DATEADD('month', -3, CURRENT_DATE()) \n",
        "                   THEN o.order_id END)::FLOAT AS recent_orders,\n",
        "    -- Historical average\n",
        "    (COUNT(DISTINCT CASE WHEN o.order_date < DATEADD('month', -3, CURRENT_DATE()) \n",
        "                    THEN o.order_id END) / 9.0)::FLOAT AS historical_avg_orders,\n",
        "    -- Support satisfaction\n",
        "    AVG(CASE WHEN st.created_date >= DATEADD('month', -6, CURRENT_DATE()) \n",
        "        THEN st.customer_satisfaction_score::FLOAT END) AS avg_csat,\n",
        "    -- Quality issues\n",
        "    COUNT(DISTINCT qi.quality_issue_id)::FLOAT AS quality_issue_count,\n",
        "    -- Device deployments\n",
        "    COUNT(DISTINCT CASE WHEN dd.deployment_date >= DATEADD('month', -12, CURRENT_DATE()) \n",
        "                   THEN dd.deployment_id END)::FLOAT AS recent_device_deployments,\n",
        "    -- Target: Is churned (simplified logic)\n",
        "    (a.agency_status = 'CHURNED')::BOOLEAN AS is_churned\n",
        "FROM RAW.AGENCIES a\n",
        "LEFT JOIN RAW.ORDERS o ON a.agency_id = o.agency_id\n",
        "LEFT JOIN RAW.SUPPORT_TICKETS st ON a.agency_id = st.agency_id\n",
        "LEFT JOIN RAW.QUALITY_ISSUES qi ON a.agency_id = qi.agency_id\n",
        "LEFT JOIN RAW.DEVICE_DEPLOYMENTS dd ON a.agency_id = dd.agency_id\n",
        "WHERE a.agency_status IN ('ACTIVE', 'CHURNED')  -- Only include active or churned agencies\n",
        "GROUP BY a.agency_id, a.agency_type, a.jurisdiction_type, a.lifetime_value, a.population_served, a.agency_status\n",
        "HAVING COUNT(DISTINCT o.order_id) > 0  -- Changed from 10 to 0 (any orders)\n",
        "   OR COUNT(DISTINCT dd.deployment_id) > 0  -- OR has any deployments\n",
        "LIMIT 5000  -- Limit to 5000 agencies for faster training\n",
        "\"\"\")\n",
        "\n",
        "print(f\"Churn data: {churn_df.count()} agencies\")\n",
        "churn_df.show(5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Train Churn Classification Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train/test split (80/20)\n",
        "train_churn, test_churn = churn_df.random_split([0.8, 0.2], seed=42)\n",
        "\n",
        "# Drop AGENCY_ID\n",
        "train_churn = train_churn.drop(\"AGENCY_ID\")\n",
        "test_churn = test_churn.drop(\"AGENCY_ID\")\n",
        "\n",
        "# Create pipeline with preprocessing and classification\n",
        "churn_pipeline = Pipeline([\n",
        "    (\"Encoder\", OneHotEncoder(\n",
        "        input_cols=[\"AGENCY_SEGMENT\", \"JURISDICTION\"],\n",
        "        output_cols=[\"AGENCY_SEGMENT_ENCODED\", \"JURISDICTION_ENCODED\"],\n",
        "        drop_input_cols=True,  # Drop original string columns after encoding\n",
        "        handle_unknown=\"ignore\"\n",
        "    )),\n",
        "    (\"Classifier\", RandomForestClassifier(\n",
        "        label_cols=[\"IS_CHURNED\"],\n",
        "        output_cols=[\"CHURN_PREDICTION\"],\n",
        "        n_estimators=100,\n",
        "        max_depth=10\n",
        "    ))\n",
        "])\n",
        "\n",
        "# Train model\n",
        "churn_pipeline.fit(train_churn)\n",
        "print(\"✅ Churn classification model trained\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluate and Register Churn Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Make predictions\n",
        "churn_predictions = churn_pipeline.predict(test_churn)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(df=churn_predictions, y_true_col_names=\"IS_CHURNED\", y_pred_col_names=\"CHURN_PREDICTION\")\n",
        "# Note: ROC AUC might need probability scores - using accuracy for now\n",
        "churn_metrics = {\"accuracy\": round(accuracy, 4)}\n",
        "print(f\"Churn model metrics: {churn_metrics}\")\n",
        "\n",
        "# Register model (use different name to avoid conflict)\n",
        "reg.log_model(\n",
        "    model=churn_pipeline,\n",
        "    model_name=\"AGENCY_CHURN_PREDICTOR\",\n",
        "    version_name=\"V1\",\n",
        "    comment=\"Predicts customer churn probability using Random Forest based on behavior patterns\",\n",
        "    metrics=churn_metrics\n",
        ")\n",
        "\n",
        "print(\"✅ Churn model registered to Model Registry as AGENCY_CHURN_PREDICTOR\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# MODEL 3: Device Deployment Success Prediction\n",
        "\n",
        "Predict which design wins are likely to convert to production orders.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Prepare Device Deployment Success Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get device deployment features\n",
        "deployment_success_df = session.sql(\"\"\"\n",
        "SELECT\n",
        "    dd.deployment_id,\n",
        "    p.product_family,\n",
        "    a.agency_type AS agency_segment,\n",
        "    a.jurisdiction_type AS jurisdiction,\n",
        "    a.population_served::FLOAT AS population_served,\n",
        "    dd.competitive_replacement::BOOLEAN AS is_competitive_win,\n",
        "    o.officer_status,\n",
        "    o.axon_certified::BOOLEAN AS officer_certified,\n",
        "    -- Deployment success: has evidence uploads and still active\n",
        "    (dd.deployment_status = 'ACTIVE' \n",
        "     AND EXISTS (SELECT 1 FROM RAW.EVIDENCE_UPLOADS ev \n",
        "                 WHERE ev.deployment_id = dd.deployment_id))::BOOLEAN AS deployment_successful\n",
        "FROM RAW.DEVICE_DEPLOYMENTS dd\n",
        "JOIN RAW.PRODUCT_CATALOG p ON dd.product_id = p.product_id\n",
        "JOIN RAW.AGENCIES a ON dd.agency_id = a.agency_id\n",
        "JOIN RAW.OFFICERS o ON dd.officer_id = o.officer_id\n",
        "WHERE dd.deployment_date >= DATEADD('month', -24, CURRENT_DATE())\n",
        "\"\"\")\n",
        "\n",
        "print(f\"Deployment data: {deployment_success_df.count()} deployments\")\n",
        "deployment_success_df.show(5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Train Conversion Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split data\n",
        "train_deployment_success, test_deployment_success = deployment_success_df.random_split([0.8, 0.2], seed=42)\n",
        "\n",
        "# Drop DEPLOYMENT_ID (VARCHAR not supported as feature)\n",
        "train_deployment_success = train_deployment_success.drop(\"DEPLOYMENT_ID\")\n",
        "test_deployment_success = test_deployment_success.drop(\"DEPLOYMENT_ID\")\n",
        "\n",
        "# Create pipeline\n",
        "deployment_success_pipeline = Pipeline([\n",
        "    (\"Encoder\", OneHotEncoder(\n",
        "        input_cols=[\"PRODUCT_FAMILY\", \"AGENCY_SEGMENT\", \"JURISDICTION\", \"OFFICER_STATUS\"],\n",
        "        output_cols=[\"PRODUCT_FAMILY_ENC\", \"AGENCY_SEGMENT_ENC\", \"JURISDICTION_ENC\", \"OFFICER_STATUS_ENC\"],\n",
        "        drop_input_cols=True,  # Drop original string columns after encoding\n",
        "        handle_unknown=\"ignore\"\n",
        "    )),\n",
        "    (\"Classifier\", LogisticRegression(\n",
        "        label_cols=[\"DEPLOYMENT_SUCCESSFUL\"],\n",
        "        output_cols=[\"SUCCESS_PREDICTION\"]\n",
        "    ))\n",
        "])\n",
        "\n",
        "# Train\n",
        "deployment_success_pipeline.fit(train_deployment_success)\n",
        "print(\"✅ Deployment success model trained\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluate and Register Conversion Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Predict on test set\n",
        "deployment_success_predictions = deployment_success_pipeline.predict(test_deployment_success)\n",
        "\n",
        "# Calculate accuracy\n",
        "success_accuracy = accuracy_score(df=deployment_success_predictions, \n",
        "                                   y_true_col_names=\"DEPLOYMENT_SUCCESSFUL\",\n",
        "                                   y_pred_col_names=\"SUCCESS_PREDICTION\")\n",
        "success_metrics = {\"accuracy\": round(success_accuracy, 4)}\n",
        "print(f\"Deployment success model metrics: {success_metrics}\")\n",
        "\n",
        "# Register model\n",
        "reg.log_model(\n",
        "    model=deployment_success_pipeline,\n",
        "    model_name=\"DEPLOYMENT_SUCCESS_PREDICTOR\",\n",
        "    version_name=\"V1\",\n",
        "    comment=\"Predicts deployment success (active with evidence uploads) using Logistic Regression based on officer, agency, and product features\",\n",
        "    metrics=success_metrics\n",
        ")\n",
        "\n",
        "print(\"✅ Deployment success model registered to Model Registry as DEPLOYMENT_SUCCESS_PREDICTOR\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Verify Models in Registry\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Show all models in the registry\n",
        "print(\"Models in registry:\")\n",
        "reg.show_models()\n",
        "\n",
        "# Show versions for evidence volume model\n",
        "print(\"\\nEvidence Volume Predictor versions:\")\n",
        "reg.get_model(\"EVIDENCE_VOLUME_PREDICTOR\").show_versions()\n",
        "\n",
        "# Show versions for churn model  \n",
        "print(\"\\nAgency Churn Predictor versions:\")\n",
        "reg.get_model(\"AGENCY_CHURN_PREDICTOR\").show_versions()\n",
        "\n",
        "# Show versions for deployment success model\n",
        "print(\"\\nDeployment Success Predictor versions:\")\n",
        "reg.get_model(\"DEPLOYMENT_SUCCESS_PREDICTOR\").show_versions()\n",
        "\n",
        "print(\"\\n✅ All models registered and ready to add to Intelligence Agent\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Test Model Inference\n",
        "\n",
        "Test calling each model to make predictions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test evidence volume forecast on recent data\n",
        "evidence_upload_volume_model = reg.get_model(\"EVIDENCE_VOLUME_PREDICTOR\").default\n",
        "recent_evidence_upload_volume = evidence_upload_volume_df.limit(3).drop(\"UPLOAD_MONTH\")\n",
        "evidence_upload_volume_preds = evidence_upload_volume_model.run(recent_evidence_upload_volume, function_name=\"predict\")\n",
        "print(\"Evidence Volume predictions:\")\n",
        "evidence_upload_volume_preds.select(\"TOTAL_EVIDENCE_UPLOAD_VOLUME\", \"PREDICTED_EVIDENCE_UPLOAD_VOLUME\").show()\n",
        "\n",
        "# Test churn prediction on sample agencies\n",
        "churn_model = reg.get_model(\"AGENCY_CHURN_PREDICTOR\").default\n",
        "sample_agencies = churn_df.limit(5).drop(\"AGENCY_ID\")\n",
        "churn_preds = churn_model.run(sample_agencies, function_name=\"predict\")\n",
        "print(\"\\nChurn predictions:\")\n",
        "churn_preds.select(\"IS_CHURNED\", \"CHURN_PREDICTION\").show()\n",
        "\n",
        "# Test deployment success prediction\n",
        "deployment_success_model = reg.get_model(\"DEPLOYMENT_SUCCESS_PREDICTOR\").default\n",
        "sample_deployments = deployment_success_df.limit(5).drop(\"DEPLOYMENT_ID\")\n",
        "deployment_success_preds = deployment_success_model.run(sample_deployments, function_name=\"predict\")\n",
        "print(\"\\nDeployment Success predictions:\")\n",
        "deployment_success_preds.select(\"DEPLOYMENT_SUCCESSFUL\", \"SUCCESS_PREDICTION\").show()\n",
        "\n",
        "print(\"\\n✅ All models tested successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Next Steps\n",
        "\n",
        "## Add Models to Intelligence Agent\n",
        "\n",
        "**Option 1: Using the SQL Script (Easiest)**\n",
        "Run `sql/agent/08_create_intelligence_agent.sql` which automatically configures all 3 ML models.\n",
        "\n",
        "**Option 2: Manual Configuration in Snowsight**\n",
        "1. In Snowsight → AI & ML → Agents → AXON_INTELLIGENCE_AGENT\n",
        "2. Go to Tools → + Add → Function\n",
        "3. Add each model wrapper procedure:\n",
        "   - **PREDICT_EVIDENCE_UPLOAD_VOLUME** (from `sql/ml/07_create_model_wrapper_functions.sql`)\n",
        "   - **PREDICT_AGENCY_CHURN** (from `sql/ml/07_create_model_wrapper_functions.sql`)\n",
        "   - **PREDICT_DEPLOYMENT_SUCCESS** (from `sql/ml/07_create_model_wrapper_functions.sql`)\n",
        "\n",
        "## Example Questions for Agent\n",
        "\n",
        "- \"Predict evidence upload volume for the next 6 months\"\n",
        "- \"Which agencies are at high risk of churn?\"\n",
        "- \"What is the predicted success rate for deploying Body Camera 3 to Officer OFC00012345?\"\n",
        "- \"Forecast storage needs for Evidence.com over the next quarter\"\n",
        "\n",
        "The models will now be available as tools your agent can use!\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "snowflake": {
      "packages": [
        "snowflake-ml-python",
        "scikit-learn",
        "xgboost",
        "matplotlib"
      ]
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
