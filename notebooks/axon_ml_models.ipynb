{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Axon ML Models - Model Registry\n",
        "\n",
        "This notebook trains ML models for the Axon Intelligence Agent:\n",
        "- **Evidence Upload Volume Forecasting** - Predict future monthly evidence_upload_volume\n",
        "- **Agency Churn Prediction** - Classify agencies at risk of churning\n",
        "- **Device Deployment Success** - Predict which device deployments will be successful\n",
        "\n",
        "All models are registered to Snowflake Model Registry and can be added as tools to the Intelligence Agent.\n",
        "\n",
        "## Before You Begin\n",
        "\n",
        "**Add these packages** in the Packages dropdown (upper right):\n",
        "- `snowflake-ml-python`\n",
        "- `scikit-learn`\n",
        "- `xgboost`\n",
        "- `matplotlib`\n",
        "\n",
        "**Database:** AXON_INTELLIGENCE  \n",
        "**Schema:** ANALYTICS  \n",
        "**Warehouse:** AXON_WH\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import Required Packages\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import Python packages\n",
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Import Snowpark\n",
        "from snowflake.snowpark.context import get_active_session\n",
        "import snowflake.snowpark.functions as F\n",
        "import snowflake.snowpark.types as T\n",
        "from snowflake.snowpark import Window\n",
        "\n",
        "# Import Snowpark ML\n",
        "from snowflake.ml.modeling.preprocessing import StandardScaler, OneHotEncoder\n",
        "from snowflake.ml.modeling.pipeline import Pipeline\n",
        "from snowflake.ml.modeling.linear_model import LinearRegression, LogisticRegression\n",
        "from snowflake.ml.modeling.ensemble import RandomForestClassifier\n",
        "from snowflake.ml.modeling.metrics import mean_squared_error, mean_absolute_error, accuracy_score, roc_auc_score\n",
        "from snowflake.ml.registry import Registry\n",
        "\n",
        "print(\"✅ Packages imported successfully\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Connect to Snowflake\n",
        "\n",
        "Get active session and set context to Axon database.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get active Snowflake session\n",
        "session = get_active_session()\n",
        "\n",
        "# Set context\n",
        "session.use_database('AXON_INTELLIGENCE')\n",
        "session.use_schema('ANALYTICS')\n",
        "session.use_warehouse('AXON_WH')\n",
        "\n",
        "print(f\"✅ Connected - Role: {session.get_current_role()}\")\n",
        "print(f\"   Warehouse: {session.get_current_warehouse()}\")\n",
        "print(f\"   Database.Schema: {session.get_fully_qualified_current_schema()}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# MODEL 1: Evidence Upload Volume Forecasting\n",
        "\n",
        "Predict future monthly evidence_upload_volume using historical order data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Prepare Revenue Training Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get monthly evidence_upload_volume data with features\n",
        "evidence_upload_volume_df = session.sql(\"\"\"\n",
        "SELECT\n",
        "    DATE_TRUNC('month', order_date)::DATE AS order_month,\n",
        "    MONTH(order_date) AS month_num,\n",
        "    YEAR(order_date) AS year_num,\n",
        "    SUM(order_amount)::FLOAT AS total_evidence_upload_volume,\n",
        "    COUNT(DISTINCT order_id)::FLOAT AS order_count,\n",
        "    COUNT(DISTINCT agency_id)::FLOAT AS customer_count,\n",
        "    AVG(order_amount)::FLOAT AS avg_order_value\n",
        "FROM RAW.ORDERS\n",
        "WHERE order_date >= DATEADD('month', -30, CURRENT_DATE())\n",
        "  AND payment_status = 'COMPLETED'\n",
        "GROUP BY DATE_TRUNC('month', order_date), MONTH(order_date), YEAR(order_date)\n",
        "ORDER BY order_month\n",
        "\"\"\")\n",
        "\n",
        "print(f\"Revenue data: {evidence_upload_volume_df.count()} months\")\n",
        "evidence_upload_volume_df.show(5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Split Data and Train Revenue Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train/test split (last 6 months for testing)\n",
        "train_evidence_upload_volume = evidence_upload_volume_df.filter(F.col(\"ORDER_MONTH\") < F.dateadd(\"month\", F.lit(-6), F.current_date()))\n",
        "test_evidence_upload_volume = evidence_upload_volume_df.filter(F.col(\"ORDER_MONTH\") >= F.dateadd(\"month\", F.lit(-6), F.current_date()))\n",
        "\n",
        "# Drop ORDER_MONTH (DATE type not supported in pipeline)\n",
        "train_evidence_upload_volume = train_evidence_upload_volume.drop(\"ORDER_MONTH\")\n",
        "test_evidence_upload_volume = test_evidence_upload_volume.drop(\"ORDER_MONTH\")\n",
        "\n",
        "# Create pipeline\n",
        "evidence_upload_volume_pipeline = Pipeline([\n",
        "    (\"Scaler\", StandardScaler(\n",
        "        input_cols=[\"MONTH_NUM\", \"ORDER_COUNT\", \"AGENCY_COUNT\", \"AVG_ORDER_VALUE\"],\n",
        "        output_cols=[\"MONTH_NUM_SCALED\", \"ORDER_COUNT_SCALED\", \"AGENCY_COUNT_SCALED\", \"AVG_ORDER_VALUE_SCALED\"]\n",
        "    )),\n",
        "    (\"LinearRegression\", LinearRegression(\n",
        "        label_cols=[\"TOTAL_REVENUE\"],\n",
        "        output_cols=[\"PREDICTED_REVENUE\"]\n",
        "    ))\n",
        "])\n",
        "\n",
        "# Train model\n",
        "evidence_upload_volume_pipeline.fit(train_evidence_upload_volume)\n",
        "print(\"✅ Revenue forecasting model trained\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluate and Register Revenue Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Make predictions on test set\n",
        "test_predictions = evidence_upload_volume_pipeline.predict(test_evidence_upload_volume)\n",
        "\n",
        "# Calculate metrics\n",
        "mae = mean_absolute_error(df=test_predictions, y_true_col_names=\"TOTAL_REVENUE\", y_pred_col_names=\"PREDICTED_REVENUE\")\n",
        "mse = mean_squared_error(df=test_predictions, y_true_col_names=\"TOTAL_REVENUE\", y_pred_col_names=\"PREDICTED_REVENUE\")\n",
        "rmse = mse ** 0.5\n",
        "\n",
        "metrics = {\"mae\": round(mae, 2), \"rmse\": round(rmse, 2)}\n",
        "print(f\"Model metrics: {metrics}\")\n",
        "\n",
        "# Register model (use different name to avoid conflict with ML Functions)\n",
        "reg = Registry(session)\n",
        "reg.log_model(\n",
        "    model=evidence_upload_volume_pipeline,\n",
        "    model_name=\"EVIDENCE_VOLUME_PREDICTOR\",\n",
        "    version_name=\"V1\",\n",
        "    comment=\"Predicts monthly evidence_upload_volume based on historical order patterns using Linear Regression\",\n",
        "    metrics=metrics\n",
        ")\n",
        "\n",
        "print(\"✅ Revenue model registered to Model Registry as EVIDENCE_VOLUME_PREDICTOR\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# MODEL 2: Agency Churn Prediction\n",
        "\n",
        "Classify agencies as likely to churn or not based on behavior patterns.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Prepare Churn Training Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get customer features for churn prediction\n",
        "churn_df = session.sql(\"\"\"\n",
        "SELECT\n",
        "    c.agency_id,\n",
        "    c.customer_segment,\n",
        "    c.industry_vertical,\n",
        "    c.lifetime_value::FLOAT AS lifetime_value,\n",
        "    c.credit_risk_score::FLOAT AS credit_risk_score,\n",
        "    -- Recent orders (last 3 months)\n",
        "    COUNT(DISTINCT CASE WHEN o.order_date >= DATEADD('month', -3, CURRENT_DATE()) \n",
        "                   THEN o.order_id END)::FLOAT AS recent_orders,\n",
        "    -- Historical average\n",
        "    (COUNT(DISTINCT CASE WHEN o.order_date < DATEADD('month', -3, CURRENT_DATE()) \n",
        "                    THEN o.order_id END) / 9.0)::FLOAT AS historical_avg_orders,\n",
        "    -- Support satisfaction\n",
        "    AVG(CASE WHEN st.created_date >= DATEADD('month', -6, CURRENT_DATE()) \n",
        "        THEN st.customer_satisfaction_score::FLOAT END) AS avg_csat,\n",
        "    -- Quality issues\n",
        "    COUNT(DISTINCT qi.quality_issue_id)::FLOAT AS quality_issue_count,\n",
        "    -- Design wins\n",
        "    COUNT(DISTINCT CASE WHEN dw.device_deployment_date >= DATEADD('month', -12, CURRENT_DATE()) \n",
        "                   THEN dw.device_deployment_id END)::FLOAT AS recent_device_deployments,\n",
        "    -- Target: Is churned\n",
        "    (c.customer_status = 'CHURNED' \n",
        "     OR (COUNT(DISTINCT CASE WHEN o.order_date >= DATEADD('month', -3, CURRENT_DATE()) \n",
        "                        THEN o.order_id END) = 0 \n",
        "         AND COUNT(DISTINCT CASE WHEN o.order_date < DATEADD('month', -3, CURRENT_DATE()) \n",
        "                            THEN o.order_id END) > 5))::BOOLEAN AS is_churned\n",
        "FROM RAW.AGENCIES c\n",
        "LEFT JOIN RAW.ORDERS o ON c.agency_id = o.agency_id\n",
        "LEFT JOIN RAW.SUPPORT_TICKETS st ON c.agency_id = st.agency_id\n",
        "LEFT JOIN RAW.QUALITY_ISSUES qi ON c.agency_id = qi.agency_id\n",
        "LEFT JOIN RAW.DEVICE_DEPLOYMENTS dw ON c.agency_id = dw.agency_id\n",
        "GROUP BY c.agency_id, c.customer_segment, c.industry_vertical, c.lifetime_value, c.credit_risk_score, c.customer_status\n",
        "HAVING COUNT(DISTINCT o.order_id) > 10\n",
        "\"\"\")\n",
        "\n",
        "print(f\"Churn data: {churn_df.count()} agencies\")\n",
        "churn_df.show(5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Train Churn Classification Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train/test split (80/20)\n",
        "train_churn, test_churn = churn_df.random_split([0.8, 0.2], seed=42)\n",
        "\n",
        "# Drop AGENCY_ID and drop original string columns after they'll be encoded\n",
        "train_churn = train_churn.drop(\"AGENCY_ID\")\n",
        "test_churn = test_churn.drop(\"AGENCY_ID\")\n",
        "\n",
        "# Create pipeline with preprocessing and classification\n",
        "churn_pipeline = Pipeline([\n",
        "    (\"Encoder\", OneHotEncoder(\n",
        "        input_cols=[\"AGENCY_SEGMENT\", \"INDUSTRY_VERTICAL\"],\n",
        "        output_cols=[\"AGENCY_SEGMENT_ENCODED\", \"INDUSTRY_VERTICAL_ENCODED\"],\n",
        "        drop_input_cols=True,  # Drop original string columns after encoding\n",
        "        handle_unknown=\"ignore\"\n",
        "    )),\n",
        "    (\"Classifier\", RandomForestClassifier(\n",
        "        label_cols=[\"IS_CHURNED\"],\n",
        "        output_cols=[\"CHURN_PREDICTION\"],\n",
        "        n_estimators=100,\n",
        "        max_depth=10\n",
        "    ))\n",
        "])\n",
        "\n",
        "# Train model\n",
        "churn_pipeline.fit(train_churn)\n",
        "print(\"✅ Churn classification model trained\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluate and Register Churn Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Make predictions\n",
        "churn_predictions = churn_pipeline.predict(test_churn)\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(df=churn_predictions, y_true_col_names=\"IS_CHURNED\", y_pred_col_names=\"CHURN_PREDICTION\")\n",
        "# Note: ROC AUC might need probability scores - using accuracy for now\n",
        "churn_metrics = {\"accuracy\": round(accuracy, 4)}\n",
        "print(f\"Churn model metrics: {churn_metrics}\")\n",
        "\n",
        "# Register model (use different name to avoid conflict)\n",
        "reg.log_model(\n",
        "    model=churn_pipeline,\n",
        "    model_name=\"AGENCY_CHURN_PREDICTOR\",\n",
        "    version_name=\"V1\",\n",
        "    comment=\"Predicts customer churn probability using Random Forest based on behavior patterns\",\n",
        "    metrics=churn_metrics\n",
        ")\n",
        "\n",
        "print(\"✅ Churn model registered to Model Registry as AGENCY_CHURN_PREDICTOR\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# MODEL 3: Device Deployment Success Prediction\n",
        "\n",
        "Predict which design wins are likely to convert to production orders.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Prepare Device Deployment Success Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get design win features\n",
        "deployment_success_df = session.sql(\"\"\"\n",
        "SELECT\n",
        "    dw.device_deployment_id,\n",
        "    p.product_family,\n",
        "    c.customer_segment,\n",
        "    c.industry_vertical,\n",
        "    dw.estimated_annual_volume::FLOAT AS estimated_volume,\n",
        "    dw.competitive_displacement::BOOLEAN AS is_competitive_win,\n",
        "    -- Has this design gone to production?\n",
        "    (EXISTS (SELECT 1 FROM RAW.PRODUCTION_ORDERS po \n",
        "             WHERE po.device_deployment_id = dw.device_deployment_id))::BOOLEAN AS converted_to_production\n",
        "FROM RAW.DEVICE_DEPLOYMENTS dw\n",
        "JOIN RAW.PRODUCT_CATALOG p ON dw.product_id = p.product_id\n",
        "JOIN RAW.AGENCIES c ON dw.agency_id = c.agency_id\n",
        "WHERE dw.device_deployment_date >= DATEADD('month', -24, CURRENT_DATE())\n",
        "\"\"\")\n",
        "\n",
        "print(f\"Design win data: {deployment_success_df.count()} design wins\")\n",
        "deployment_success_df.show(5)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Train Conversion Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split data\n",
        "train_deployment_success, test_deployment_success = deployment_success_df.random_split([0.8, 0.2], seed=42)\n",
        "\n",
        "# Drop DESIGN_WIN_ID (VARCHAR not supported as feature)\n",
        "train_deployment_success = train_deployment_success.drop(\"DESIGN_WIN_ID\")\n",
        "test_deployment_success = test_deployment_success.drop(\"DESIGN_WIN_ID\")\n",
        "\n",
        "# Create pipeline\n",
        "deployment_success_pipeline = Pipeline([\n",
        "    (\"Encoder\", OneHotEncoder(\n",
        "        input_cols=[\"PRODUCT_FAMILY\", \"AGENCY_SEGMENT\", \"INDUSTRY_VERTICAL\"],\n",
        "        output_cols=[\"PRODUCT_FAMILY_ENC\", \"AGENCY_SEGMENT_ENC\", \"INDUSTRY_VERTICAL_ENC\"],\n",
        "        drop_input_cols=True,  # Drop original string columns after encoding\n",
        "        handle_unknown=\"ignore\"\n",
        "    )),\n",
        "    (\"Classifier\", LogisticRegression(\n",
        "        label_cols=[\"CONVERTED_TO_PRODUCTION\"],\n",
        "        output_cols=[\"CONVERSION_PREDICTION\"]\n",
        "    ))\n",
        "])\n",
        "\n",
        "# Train\n",
        "deployment_success_pipeline.fit(train_deployment_success)\n",
        "print(\"✅ Design win deployment_success model trained\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Evaluate and Register Conversion Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Predict on test set\n",
        "deployment_success_predictions = deployment_success_pipeline.predict(test_deployment_success)\n",
        "\n",
        "# Calculate accuracy\n",
        "conv_accuracy = accuracy_score(df=deployment_success_predictions, \n",
        "                                y_true_col_names=\"CONVERTED_TO_PRODUCTION\",\n",
        "                                y_pred_col_names=\"CONVERSION_PREDICTION\")\n",
        "conv_metrics = {\"accuracy\": round(conv_accuracy, 4)}\n",
        "print(f\"Conversion model metrics: {conv_metrics}\")\n",
        "\n",
        "# Register model (use different name to avoid conflict)\n",
        "reg.log_model(\n",
        "    model=deployment_success_pipeline,\n",
        "    model_name=\"DEPLOYMENT_SUCCESS_PREDICTOR\",\n",
        "    version_name=\"V1\",\n",
        "    comment=\"Predicts design win to production deployment_success using Logistic Regression\",\n",
        "    metrics=conv_metrics\n",
        ")\n",
        "\n",
        "print(\"✅ Conversion model registered to Model Registry as DEPLOYMENT_SUCCESS_PREDICTOR\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Verify Models in Registry\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Show all models in the registry\n",
        "print(\"Models in registry:\")\n",
        "reg.show_models()\n",
        "\n",
        "# Show versions for evidence_upload_volume model\n",
        "print(\"\\nRevenue model versions:\")\n",
        "reg.get_model(\"EVIDENCE_VOLUME_PREDICTOR\").show_versions()\n",
        "\n",
        "# Show versions for churn model  \n",
        "print(\"\\nChurn model versions:\")\n",
        "reg.get_model(\"AGENCY_CHURN_PREDICTOR\").show_versions()\n",
        "\n",
        "# Show versions for deployment_success model\n",
        "print(\"\\nConversion model versions:\")\n",
        "reg.get_model(\"DEPLOYMENT_SUCCESS_PREDICTOR\").show_versions()\n",
        "\n",
        "print(\"\\n✅ All models registered and ready to add to Intelligence Agent\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Test Model Inference\n",
        "\n",
        "Test calling each model to make predictions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test evidence_upload_volume forecast on recent data\n",
        "evidence_upload_volume_model = reg.get_model(\"EVIDENCE_VOLUME_PREDICTOR\").default\n",
        "recent_evidence_upload_volume = evidence_upload_volume_df.limit(3).drop(\"ORDER_MONTH\")\n",
        "evidence_upload_volume_preds = evidence_upload_volume_model.run(recent_evidence_upload_volume, function_name=\"predict\")\n",
        "print(\"Revenue predictions:\")\n",
        "evidence_upload_volume_preds.select(\"TOTAL_REVENUE\", \"PREDICTED_REVENUE\").show()\n",
        "\n",
        "# Test churn prediction on sample agencies\n",
        "churn_model = reg.get_model(\"AGENCY_CHURN_PREDICTOR\").default\n",
        "sample_agencies = churn_df.limit(5).drop(\"AGENCY_ID\")\n",
        "churn_preds = churn_model.run(sample_agencies, function_name=\"predict\")\n",
        "print(\"\\nChurn predictions:\")\n",
        "churn_preds.select(\"IS_CHURNED\", \"CHURN_PREDICTION\").show()\n",
        "\n",
        "# Test deployment_success prediction\n",
        "deployment_success_model = reg.get_model(\"DEPLOYMENT_SUCCESS_PREDICTOR\").default\n",
        "sample_designs = deployment_success_df.limit(5).drop(\"DESIGN_WIN_ID\")\n",
        "deployment_success_preds = deployment_success_model.run(sample_designs, function_name=\"predict\")\n",
        "print(\"\\nConversion predictions:\")\n",
        "deployment_success_preds.select(\"CONVERTED_TO_PRODUCTION\", \"CONVERSION_PREDICTION\").show()\n",
        "\n",
        "print(\"\\n✅ All models tested successfully!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Next Steps\n",
        "\n",
        "## Add Models to Intelligence Agent\n",
        "\n",
        "1. In Snowsight → AI & ML → Agents → AXON_INTELLIGENCE_AGENT\n",
        "2. Go to Tools → + Add → Model\n",
        "3. Add each registered model:\n",
        "   - **EVIDENCE_VOLUME_PREDICTOR**\n",
        "   - **AGENCY_CHURN_PREDICTOR**\n",
        "   - **DEPLOYMENT_SUCCESS_PREDICTOR**\n",
        "\n",
        "## Example Questions for Agent\n",
        "\n",
        "- \"Forecast evidence_upload_volume for the next quarter using the evidence_upload_volume predictor\"\n",
        "- \"Which agencies are predicted to churn according to the churn predictor?\"\n",
        "- \"Show me design wins with high deployment_success probability using the deployment_success predictor\"\n",
        "\n",
        "The models will now be available as tools your agent can use!\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
